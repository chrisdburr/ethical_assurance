---
title: What is ethical assurance?
author: chris
excerpt: "This guide introduces the methodology of ethical assurance: a process of using structured argumentation to provide assurance to another party (or parties) that a particular claim (or set of related claims) about a normative property of a system is warranted given the available evidence."
image_path: /assets/img/optics.jpeg
related_guides: why-is-ethical-assurance-important the-value-of-stakeholder-engagement
---

Assurance is a process of establishing trust.

> "Will this rickety bridge carry my weight? Will my close friend keep their promise? What about that politician?"

Whether we trust _someone_ or _some object_ depends, in part, on the evidence we have to help us evaluate whether there are good grounds for placing trust.
In other words, what is the evidence of their trustworthiness?

While there are occasions where a careful and thorough evaluation of trustworthiness would be inappropriate or insensitive (e.g., if a partner or spouse asks you to "_just trust them_"), there are also times where placing trust blindly would be irresponsible.
For instance, if a healthcare provider purchases a new diagnostic tool that uses machine learning to analyse patient's electronic health records without asking key questions of the system's developer we would say there were acting irresponsibly.
Their position of authority and the obligation they have towards key stakeholders requires them to exercise a sufficient level of due diligence in evaluating the claims of the developer, and in some cases carrying out careful assessments of the product or service prior to procurement (e.g., data protection impact assessment).

A wide variety of laws, regulation, and best practices exist to help with such assessments, and international organisations also exist to help maintain common standards.
But when it comes to evaluating the _ethical properties_ of a system or service, especially one that relies on machine learning or AI, the story is quite different.

There are many reasons for this, including (but not limited to) the following:

1. Machine learning algorithms often operate _in the background_. As users, we interact with them through digital interfaces, such as an app on our smartphone, and so the manner in which they shape our behaviour or choices is not always obvious to us.
2. AI can be remarkably complex and also interacts with complex human structures or institutions. Trying to disentangle this knotted web of processes poses a challenge to thorough assessment and auditing.
3. Many new types of data-driven technology require massive amounts of data to achieve satisfactory levels of performance. In some cases these data refer to personal or sensitive attributes of humans (e.g., health or financial data). However, individuals can have differing attitudes towards the collection and use of their data.
4. Algorithms can operate across massive scales and interact with billions of people (e.g., the algorithms that power Google's search engine or generate Facebook's news feed). Although some machine learning algorithms can adjust their behaviour based on the input data they receive, there is no guarantee that the results they offer will treat different groups of people fairly.

These challenges relate to a variety of ethical concerns, such as the transparency and explainability of algorithmic systems; the impact that data-driven technologies may have on an individual's right to privacy and self-determination; the accountability of those who were responsible for developing them; and the consequences of implementing large-scale AI systems that can exacerbate existing socioeconomic injustices.

In recognition of the significance of these issues, the process of ethical assurance has been designed to promote a more reflective and responsible approach to the design, development, and deployment of data-driven technologies and algorithmic systems.

We can define ethical assurance as follows:

> Ethical assurance is a process of using structured forms of argumentation to provide assurance to affected individuals and stakeholders that a particular claim (or set of related claims) about an ethical property of a system is warranted given the available evidence. {% cite burr2021 %}

Or, to put it another way, it is a process of providing assurance that some data-driven technology or AI system is trustworthy.
It is a method for engaging affected individuals and stakeholders to help promote trust by laying out clear and publicly acceptable reasons for the ethical properties of some project or system.

Each subsequent guide provides additional details for how this method works, and how developers, users, and policy-makers can use ethical assurance to collectively foster a more responsible approach to research and innovation in data science and AI.

<h3>Footnotes</h3>